## Setting Node preferences

Considering what has been said in the previous unit, let's talk about node preferences.

There existe a field named "nodeSelector" in the pod.spec, which specifies a key-value pair that must match a label which is set on nodes that are eligible to run the Pod.

Therefore, we will show how this behave considering the following assertion, which was taken from [K8s docs](https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/)

> *"If none of the nodes are suitable, the pod remains unscheduled until the scheduler is able to place it."*

------------------------------

### Demo


First step means labeling a node:
```bash
kubectl label nodes talos-2pv-ytc environment=8.2-demo
```

&nbsp;

And before deploying the resource, cordon the node:

```bash
kubectl cordon worker2
```

Then, apply this manifest that will create a single Pod with the following specs:

```bash
kubectl apply -f pod.yaml
```

&nbsp;

```YAML
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx
    imagePullPolicy: IfNotPresent
  nodeSelector:
    environment: 8.2-demo

```

&nbsp;

Check the Pods status:
```
kubectl get pods -o wide
```

&nbsp;

New Pod will be in status "Pending" as there exist no Node on which it can be scheduled.

```bash
kubectl get pods -o wide
NAME                        READY   STATUS    RESTARTS      AGE   IP            NODE            NOMINATED NODE   READINESS GATES
ha-talos-7454d6dfcb-lxrn5   1/1     Running   3 (76m ago)   34h   10.244.0.28   talos-pmv-2qi   <none>           <none>
ha-talos-7454d6dfcb-s7dfz   1/1     Running   2 (76m ago)   34h   10.244.0.29   talos-pmv-2qi   <none>           <none>
nginx                       0/1     Pending   0             2m    <none>        <none>          <none>           <none>
```

&nbsp;

To check in detail what is going on with the Pod, lets check:
```bash
kubectl describe pod/nginx
```

The log is self-explanatory:
```bash
Warning  FailedScheduling  27s   default-scheduler  0/3 nodes are available: 1 node(s) didn't match Pod's node affinity/selector, 1 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 1 node(s) were unschedulable. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.
```

&nbsp;

Therefore, let's uncordon the labeled node to make the Pod become Running:
```bash
kubectl uncordon talos-2pv-ytc
```

Now Pod is running:
```bash
alesb-debian@Debian:~/Desktop/Lab7.6$ kubectl get pods -o wide
NAME                        READY   STATUS    RESTARTS      AGE     IP            NODE            NOMINATED NODE   READINESS GATES
ha-talos-7454d6dfcb-s7dfz   1/1     Running   2 (82m ago)   34h     10.244.0.29   talos-pmv-2qi   <none>           <none>
nginx                       1/1     Running   0             7m35s   10.244.4.2    talos-2pv-ytc   <none>           <none>
```

&nbsp;

The have a better understanding, the whole Pod-Log can be analyzed again by doing:

```bash
kubectl describe pod/nginx
```

&nbsp;

<details>
<summary>Check the whole Pod log output.</summary>

```bash
  Warning  FailedScheduling  7m58s               default-scheduler  0/3 nodes are available: 1 node(s) didn't match Pod's node affinity/selector, 1 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 1 node(s) were unschedulable. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.
  Warning  FailedScheduling  6m27s               default-scheduler  0/3 nodes are available: 1 node(s) didn't match Pod's node affinity/selector, 1 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 1 node(s) had untolerated taint {node.kubernetes.io/unreachable: }. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.
  Warning  FailedScheduling  2m (x2 over 6m24s)  default-scheduler  0/3 nodes are available: 1 node(s) didn't match Pod's node affinity/selector, 1 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 1 node(s) had untolerated taint {node.kubernetes.io/unreachable: }. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.
  Normal   Scheduled         112s                default-scheduler  Successfully assigned default/nginx to talos-2pv-ytc
  Normal   Pulling           112s                kubelet            Pulling image "nginx"
  Normal   Pulled            104s                kubelet            Successfully pulled image "nginx" in 8.039s (8.039s including waiting). Image size: 72080558 bytes.
  Normal   Created           104s                kubelet            Created container: nginx
  Normal   Started           103s                kubelet            Started container nginx
  ```
  </details>

&nbsp;

Demo is now considered demonstrated. 

Let's revert the changes:

To do it, consider the following commands.

*kubectl label node talos-2pv-ytc <labelname>-*

Which in this scenario will be:
```bash
kubectl label nodes talos-2pv-ytc environment-
node/talos-2pv-ytc unlabeled
```

Now delete the Pod:
```bash
kubectl delete -f pod.yaml
pod "nginx" deleted
```